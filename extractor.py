# extractor.py
# VERS√ÉO 2.0 - COM CLASSIFICADOR DE DOCUMENTOS
# Autor: Thiago Ribeiro
# Data: 2024
#
# MODIFICA√á√ïES:
# - Classifica√ß√£o autom√°tica do tipo de documento
# - Extra√ß√£o de pessoas (r√©us, remetentes, destinat√°rios)
# - Detec√ß√£o de anexos
# - Normaliza√ß√£o de texto (HTML entities)
# - Suporte a 7 tipos de documentos hist√≥ricos

import requests
from bs4 import BeautifulSoup
from datetime import datetime
from urllib.parse import urljoin
import re

BASE_URL = "http://showtrials.ru"

# ==============================================
# CLASSIFICADOR DE DOCUMENTOS (BASEADO EM DADOS REAIS)
# ==============================================

TIPOS_DOCUMENTO = {
    'interrogatorio': {
        'padroes': ['–ü—Ä–æ—Ç–æ–∫–æ–ª –¥–æ–ø—Ä–æ—Å–∞'],
        'prioridade': 1,
        'descricao': 'Protocolo de Interrogat√≥rio'
    },
    'acareacao': {
        'padroes': ['–ü—Ä–æ—Ç–æ–∫–æ–ª –æ—á–Ω–æ–π —Å—Ç–∞–≤–∫–∏'],
        'prioridade': 2,
        'descricao': 'Protocolo de Acarea√ß√£o'
    },
    'acusacao': {
        'padroes': [
            '–ü—Ä–æ–µ–∫—Ç –æ–±–≤–∏–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∑–∞–∫–ª—é—á–µ–Ω–∏—è',
            '–û–±–≤–∏–Ω–∏—Ç–µ–ª—å–Ω–æ–µ –∑–∞–∫–ª—é—á–µ–Ω–∏–µ'
        ],
        'prioridade': 3,
        'descricao': 'Auto de Acusa√ß√£o'
    },
    'declaracao': {
        'padroes': ['–ó–∞—è–≤–ª–µ–Ω–∏–µ'],
        'prioridade': 4,
        'descricao': 'Declara√ß√£o/Requerimento'
    },
    'carta': {
        'padroes': ['–ü–∏—Å—å–º–æ'],
        'prioridade': 5,
        'descricao': 'Correspond√™ncia'
    },
    'relatorio': {
        'padroes': ['–°–ø–µ—Ü—Å–æ–æ–±—â–µ–Ω–∏–µ'],
        'prioridade': 6,
        'descricao': 'Relat√≥rio Especial (NKVD)'
    },
    'depoimento': {
        'padroes': [
            '–ü–æ–∫–∞–∑–∞–Ω–∏—è',    # plural (j√° existe)
            '–ü–æ–∫–∞–∑–∞–Ω–∏–µ'     # singular (FALTANDO!)
        ],
        'prioridade': 7,
        'descricao': 'Depoimento Espont√¢neo'
    },
    'laudo': {
        'padroes': ['–ê–∫—Ç —Å—É–¥–µ–±–Ω–æ-–º–µ–¥–∏—Ü–∏–Ω—Å–∫–æ–≥–æ'],
        'prioridade': 8,
        'descricao': 'Laudo Pericial'
    }
}

def classificar_documento(titulo: str) -> dict:
    """
    Classifica documento e extrai metadados estruturados.
    
    Args:
        titulo: T√≠tulo original em russo
        
    Returns:
        dict: {
            'tipo': 'interrogatorio',
            'tipo_descricao': 'Protocolo de Interrogat√≥rio',
            'pessoa_principal': '–õ.–í. –ù–∏–∫–æ–ª–∞–µ–≤–∞',
            'remetente': '–ì.–ì. –Ø–≥–æ–¥–∞',
            'destinatario': '–ò.–í. –°—Ç–∞–ª–∏–Ω',
            'envolvidos': ['–ù.–°. –ê–Ω—Ç–æ–Ω–æ–≤', '–ò.–ò. –ö–æ—Ç–æ–ª—ã–Ω–æ–≤'],
            'tem_anexos': False
        }
    """
    resultado = {
        'tipo': 'desconhecido',
        'tipo_descricao': 'N√£o classificado',
        'pessoa_principal': None,
        'remetente': None,
        'destinatario': None,
        'envolvidos': [],
        'tem_anexos': False,
        'destinatario_orgao': None
    }
    
    if not titulo:
        return resultado
    
    # 1. QUAL O TIPO DE DOCUMENTO?
    for tipo, config in TIPOS_DOCUMENTO.items():
        for padrao in config['padroes']:
            if padrao in titulo:
                resultado['tipo'] = tipo
                resultado['tipo_descricao'] = config['descricao']
                break
        if resultado['tipo'] != 'desconhecido':
            break
    
    # 2. EXTRAIR PESSOAS (padr√£o: –õ.–í. –ù–∏–∫–æ–ª–∞–µ–≤–∞)
    # Pega TODAS as pessoas mencionadas no t√≠tulo
    pessoas = re.findall(r'([–ê-–Ø]\. ?[–ê-–Ø]\. [–ê-–Ø][–∞-—è]+)', titulo)
    
    if pessoas:
        # Primeira pessoa √© a principal (r√©u/interrogado)
        resultado['pessoa_principal'] = pessoas[0]
        
        # Se for acarea√ß√£o, pega os dois envolvidos
        if resultado['tipo'] == 'acareacao' and len(pessoas) >= 2:
            resultado['envolvidos'] = pessoas
        
        # Se for carta/relat√≥rio, identifica remetente/destinat√°rio
        elif resultado['tipo'] in ['carta', 'relatorio', 'declaracao']:
            if len(pessoas) >= 2:
                resultado['remetente'] = pessoas[0]
                resultado['destinatario'] = pessoas[1]
            elif len(pessoas) == 1:
                resultado['remetente'] = pessoas[0]
    
    # 3. DETECTAR DESTINAT√ÅRIO INSTITUCIONAL
    orgaos = [
        '–°–ü–û –õ–µ–Ω–∏–Ω–≥—Ä–∞–¥—Å–∫–æ–≥–æ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –ù–ö–í–î',
        '–¶–ö –í–ö–ü\(–±\)',
        '–ü–æ–ª–∏—Ç–±—é—Ä–æ –¶–ö –í–ö–ü\(–±\)',
        '–°–ª–µ–¥—Å—Ç–≤–µ–Ω–Ω—É—é –∫–æ–º–∏—Å—Å–∏—é',
        '–ê–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–∏–≤–Ω–æ–π –∫–æ–º–∏—Å—Å–∏–∏ –ù–ö–í–î'
    ]
    
    for orgao in orgaos:
        if re.search(orgao, titulo):
            resultado['destinatario_orgao'] = orgao.replace('\(', '(').replace('\)', ')')
            break
    
    # 4. TEM ANEXOS?
    resultado['tem_anexos'] = '–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ–º' in titulo.lower()
    
    return resultado


def normalizar_texto(texto: str) -> str:
    """
    Normaliza o texto extra√≠do do HTML.
    
    Corre√ß√µes:
    - HTML entities (&#39; ‚Üí ')
    - Espa√ßamento excessivo
    - Typos conhecidos (–†—É–º—è–Ω—Ü–Ω–µ–≤–∞ ‚Üí –†—É–º—è–Ω—Ü–µ–≤–∞)
    """
    if not texto:
        return texto
    
    # 1. HTML entities
    replacements = {
        '&#39;': "'",
        '&quot;': '"',
        '&amp;': '&',
        '&lt;': '<',
        '&gt;': '>',
        '&#32;': ' ',
        '&#151;': '‚Äî',
        '&#8212;': '‚Äî',
        '&#8211;': '‚Äì',
    }
    
    for entity, char in replacements.items():
        texto = texto.replace(entity, char)
    
    # 2. Typos conhecidos (baseado nos seus dados)
    typos = {
        '–†—É–º—è–Ω—Ü–Ω–µ–≤–∞': '–†—É–º—è–Ω—Ü–µ–≤–∞',
        # Adicione mais conforme encontrar
    }
    
    for errado, certo in typos.items():
        texto = texto.replace(errado, certo)
    
    # 3. Limpeza geral
    # Remove m√∫ltiplas quebras de linha
    texto = re.sub(r'\n\s*\n\s*\n', '\n\n', texto)
    # Remove espa√ßos no in√≠cio/fim das linhas
    texto = '\n'.join(line.strip() for line in texto.split('\n'))
    
    return texto.strip()


# ==============================================
# FUN√á√ïES ORIGINAIS (MANTIDAS E MELHORADAS)
# ==============================================

def coletar_links(url_indice):
    """
    Extrai lista de links da p√°gina √≠ndice.
    Mantido original, com melhorias de robustez.
    """
    print("[+] Acessando p√°gina √≠ndice...")
    
    try:
        r = requests.get(url_indice, timeout=30)
        r.encoding = "utf-8"
        r.raise_for_status()
    except Exception as e:
        print(f"[-] Erro ao acessar {url_indice}: {e}")
        return []
    
    soup = BeautifulSoup(r.text, "lxml")
    tabela = soup.find("table")
    
    if not tabela:
        print("[-] Nenhuma tabela encontrada.")
        return []
    
    links = []
    
    for row in tabela.find_all("tr"):
        colunas = row.find_all("td")
        if len(colunas) >= 2:
            data_raw = colunas[0].get_text(strip=True)
            link_tag = colunas[1].find("a")
            
            if link_tag:
                titulo = link_tag.get_text(strip=True)
                href = link_tag.get("href")
                href = urljoin(BASE_URL, href)
                
                links.append({
                    "titulo": titulo,
                    "url": href,
                    "data_original": data_raw
                })
    
    print(f"[+] {len(links)} links extra√≠dos.")
    return links


def extrair_texto(url):
    """
    Extrai e normaliza o texto do documento.
    Agora com normaliza√ß√£o autom√°tica!
    """
    try:
        r = requests.get(url, timeout=30)
        r.encoding = "utf-8"
        r.raise_for_status()
    except Exception as e:
        print(f"[-] Erro ao acessar {url}: {e}")
        return ""
    
    soup = BeautifulSoup(r.text, "lxml")
    paragrafos = soup.find_all("p")
    
    if not paragrafos:
        # Fallback: pegar todo o texto da div principal
        content = soup.find("div", class_="content") or soup.find("main") or soup
        texto_bruto = content.get_text(separator="\n", strip=True)
    else:
        texto_bruto = "\n".join(p.get_text(strip=True) for p in paragrafos)
    
    # NORMALIZA√á√ÉO AUTOM√ÅTICA!
    texto_normalizado = normalizar_texto(texto_bruto)
    
    return texto_normalizado


def montar_documento(centro, meta, texto):
    """
    Monta o documento completo com METADADOS ENRIQUECIDOS!
    Agora inclui classifica√ß√£o e pessoas extra√≠das.
    """
    # Classificar o documento pelo t√≠tulo
    classificacao = classificar_documento(meta["titulo"])
    
    # Montar documento com metadados expandidos
    documento = {
        # Metadados originais (mantidos)
        "centro": centro,
        "titulo": meta["titulo"],
        "data_original": meta["data_original"],
        "url": meta["url"],
        "texto": texto,
        "data_coleta": datetime.utcnow().isoformat(),
        
        # NOVOS METADADOS ENRIQUECIDOS!
        "tipo_documento": classificacao['tipo'],
        "tipo_descricao": classificacao['tipo_descricao'],
        "pessoa_principal": classificacao['pessoa_principal'],
        "remetente": classificacao['remetente'],
        "destinatario": classificacao['destinatario'],
        "destinatario_orgao": classificacao['destinatario_orgao'],
        "envolvidos": ', '.join(classificacao['envolvidos']) if classificacao['envolvidos'] else None,
        "tem_anexos": classificacao['tem_anexos'],
        
        # Vers√£o em ingl√™s para compatibilidade
        "tipo_en": {
            'interrogatorio': 'Interrogation',
            'acareacao': 'Confrontation',
            'acusacao': 'Indictment',
            'declaracao': 'Statement',
            'carta': 'Letter',
            'relatorio': 'Special Report',
            'depoimento': 'Testimony',
            'laudo': 'Forensic Report',
            'desconhecido': 'Unknown'
        }.get(classificacao['tipo'], 'Unknown')
    }
    
    return documento


# ==============================================
# FUN√á√ÉO DE TESTE (OPCIONAL)
# ==============================================

def testar_classificador():
    """Testa o classificador com t√≠tulos reais."""
    testes = [
        "–ü—Ä–æ—Ç–æ–∫–æ–ª –¥–æ–ø—Ä–æ—Å–∞ –õ.–í. –ù–∏–∫–æ–ª–∞–µ–≤–∞",
        "–ü—Ä–æ—Ç–æ–∫–æ–ª –æ—á–Ω–æ–π —Å—Ç–∞–≤–∫–∏ –º–µ–∂–¥—É –ù.–°. –ê–Ω—Ç–æ–Ω–æ–≤—ã–º –∏ –ò.–ò. –ö–æ—Ç–æ–ª—ã–Ω–æ–≤—ã–º",
        "–ü–∏—Å—å–º–æ –í.–í. –†—É–º—è–Ω—Ü–µ–≤–∞ —Å–µ–∫—Ä–µ—Ç–∞—Ä—é –¶–ö –í–ö–ü(–±) –ò.–í. –°—Ç–∞–ª–∏–Ω—É",
        "–°–ø–µ—Ü—Å–æ–æ–±—â–µ–Ω–∏–µ –ì.–ì. –Ø–≥–æ–¥—ã –ò.–í. –°—Ç–∞–ª–∏–Ω—É",
        "–ó–∞—è–≤–ª–µ–Ω–∏–µ –í.–ò. –ó–≤–µ–∑–¥–æ–≤–∞ –≤ –°–ü–û –õ–µ–Ω–∏–Ω–≥—Ä–∞–¥—Å–∫–æ–≥–æ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –ù–ö–í–î",
        "–ê–∫—Ç —Å—É–¥–µ–±–Ω–æ-–º–µ–¥–∏—Ü–∏–Ω—Å–∫–æ–≥–æ –≤—Å–∫—Ä—ã—Ç–∏—è —Ç—Ä—É–ø–∞ –ú.–í. –ë–æ—Ä–∏—Å–æ–≤–∞",
    ]
    
    print("\nüß™ TESTE DO CLASSIFICADOR\n")
    for titulo in testes:
        resultado = classificar_documento(titulo)
        print(f"üìÑ {titulo}")
        print(f"   ‚Üí Tipo: {resultado['tipo_descricao']} ({resultado['tipo']})")
        if resultado['pessoa_principal']:
            print(f"   ‚Üí Pessoa: {resultado['pessoa_principal']}")
        if resultado['remetente']:
            print(f"   ‚Üí De: {resultado['remetente']}")
        if resultado['destinatario']:
            print(f"   ‚Üí Para: {resultado['destinatario']}")
        if resultado['envolvidos']:
            print(f"   ‚Üí Envolvidos: {resultado['envolvidos']}")
        print()

if __name__ == "__main__":
    testar_classificador()